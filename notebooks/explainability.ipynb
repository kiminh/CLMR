{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jspijkervet/miniconda3/envs/clmr/lib/python3.7/site-packages/librosa/util/decorators.py:9: NumbaDeprecationWarning: \u001b[1mAn import was requested from a module that has moved location.\n",
      "Import requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\u001b[0m\n",
      "  from numba.decorators import jit as optional_jit\n",
      "/home/jspijkervet/miniconda3/envs/clmr/lib/python3.7/site-packages/librosa/util/decorators.py:9: NumbaDeprecationWarning: \u001b[1mAn import was requested from a module that has moved location.\n",
      "Import of 'jit' requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\u001b[0m\n",
      "  from numba.decorators import jit as optional_jit\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# TensorBoard\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from data import get_dataset\n",
    "from experiment import ex\n",
    "from model import load_model\n",
    "\n",
    "from utils import post_config_hook\n",
    "from utils.yaml_config_hook import yaml_config_hook\n",
    "from utils.eval import eval_all\n",
    "from utils.youtube import download_yt\n",
    "from datasets.utils.resample import convert_samplerate\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "cfg = yaml_config_hook(\"./config/config.yaml\")\n",
    "\n",
    "args = argparse.Namespace(**cfg)\n",
    "args.dataset = \"magnatagatune\"\n",
    "args.model_path = \"/storage/jspijkervet/logs_backup_ws7/clmr/2/\"\n",
    "args.epoch_num= 1490\n",
    "args.finetune_model_path = \"/storage/jspijkervet/logs_backup_ws7/clmr/4\"\n",
    "args.finetune_epoch_num = 50\n",
    "args.n_classes = 50 # 50 tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.lin_eval = True\n",
    "args.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "args.batch_size = args.logistic_batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Linear / Supervised training, using segmented dataset ###\n",
      "Num segments: 187060\n",
      "Num tracks: 18706\n",
      "/storage/jspijkervet/magnatagatune/statistics_segments_22050.csv\n",
      "[Train dataset (magnatagatune_segments_22050)]: Loaded mean/std: -7.70555e-05, 0.17842068\n",
      "### Linear / Supervised training, using segmented dataset ###\n",
      "Num segments: 18250\n",
      "Num tracks: 1825\n",
      "/storage/jspijkervet/magnatagatune/statistics_segments_22050.csv\n",
      "[Validation dataset (magnatagatune_segments_22050)]: Loaded mean/std: -7.70555e-05, 0.17842068\n",
      "### Linear / Supervised training, using segmented dataset ###\n",
      "Num segments: 53290\n",
      "Num tracks: 5329\n",
      "/storage/jspijkervet/magnatagatune/statistics_segments_22050.csv\n",
      "[Test dataset (magnatagatune_segments_22050)]: Loaded mean/std: -7.70555e-05, 0.17842068\n"
     ]
    }
   ],
   "source": [
    "(train_loader, train_dataset, val_loader, val_dataset, test_loader, test_dataset) = get_dataset(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### SampleCNN59049 ###\n",
      "### RELOADING CLMR MODEL FROM CHECKPOINT 1490 ###\n",
      "### Using Adam optimizer ###\n",
      "### RELOADING CLMR OPTIMIZER FROM CHECKPOINT 1490 ###\n",
      "### RELOADING SUPERVISED MODEL FROM CHECKPOINT 50 ###\n",
      "### Using Adam optimizer ###\n",
      "### RELOADING SUPERVISED OPTIMIZER FROM CHECKPOINT 50 ###\n",
      "CLMR(\n",
      "  (encoder): SampleCNN59049(\n",
      "    (conv1): Sequential(\n",
      "      (0): Conv1d(1, 128, kernel_size=(3,), stride=(3,))\n",
      "      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (conv2): Sequential(\n",
      "      (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "      (3): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (conv3): Sequential(\n",
      "      (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "      (3): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (conv4): Sequential(\n",
      "      (0): Conv1d(128, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "      (3): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (conv5): Sequential(\n",
      "      (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "      (3): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (conv6): Sequential(\n",
      "      (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "      (3): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (conv7): Sequential(\n",
      "      (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "      (3): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (conv8): Sequential(\n",
      "      (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "      (3): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (conv9): Sequential(\n",
      "      (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "      (3): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (conv10): Sequential(\n",
      "      (0): Conv1d(256, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "      (3): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (conv11): Sequential(\n",
      "      (0): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (dropout): Dropout(p=0.5, inplace=False)\n",
      "    (fc): Identity()\n",
      "  )\n",
      "  (projector): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=512, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=128, bias=False)\n",
      "  )\n",
      ")\n",
      "MLP(\n",
      "  (model): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=50, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "context_model, _, _ = load_model(args, reload_model=True, name=args.model_name)\n",
    "context_model.eval()\n",
    "\n",
    "args.n_features = context_model.n_features\n",
    "\n",
    "model, _, _ = load_model(args, reload_model=True, name=\"supervised\")\n",
    "model = model.to(args.device)\n",
    "\n",
    "print(context_model)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.current_epoch = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    taggram = []\n",
    "    for idx, x in enumerate(chunks):\n",
    "        x = x.to(args.device)\n",
    "\n",
    "        # normalise\n",
    "        if train_dataset.mean:\n",
    "            x = train_dataset.normalise_audio(x)\n",
    "\n",
    "        # add batch dim\n",
    "        x = x.unsqueeze(0)         \n",
    "        h, z = context_model(x)\n",
    "\n",
    "        output = model(h)\n",
    "        output = torch.nn.functional.softmax(output, dim=1)\n",
    "        output = output.squeeze(0) # remove batch dim\n",
    "        taggram.append(output.cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clmr",
   "language": "python",
   "name": "clmr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
