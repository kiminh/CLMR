## task / dataset options
domain: "audio" # [audio,scores]
task: "tags" # [tags,chords,symbol]
dataset: "magnatagatune" # [audio: [billboard,fma,magnatagatune] vision: [deepscores,universal]]
data_input_dir: "datasets/audio" # [audio: [datasets/audio] vision: [datasets/vision]
pretrain_dataset: "magnatagatune"
model_name: "clmr" # [clmr]
train_stage: 0
transfer: 0 # when transfer learning

## train options
seed: 42 # sacred handles automatic seeding when passed in the config
batch_size: 48 # for audio, 256 for images
num_workers: 8
start_epoch: 0
epochs: 10000

## loss options
optimizer: "Adam" # [Adam, LARS]
learning_rate: 3.0e-4 # for Adam optimizer, LARS uses batch-specific LR
weight_decay: 1.0e-6
global_lr_decay: 0.2
temperature: 0.5 # (NOTE: 0.1 goes very fast) see appendix B.7.: Optimal temperature under different batch sizes
momentum: 0.9 # SGD

## supervised params
supervised: False # to attach a FC layer
supervised_lr: 0.01

## model options
normalize: True
projection_dim: 128
dropout: 0.5

## audio
audio_length: 59049
sample_rate: 22050

## CPC
prediction_step: 20 # Time steps k to predict into future
negative_samples: 15 # Number of negative samples to be used for training
subsample: True # Boolean to decide whether to subsample from the total sequence lengh within intermediate layers


## CLMR
new_encoder: 0
### transformations
transforms_phase: 0.8
transforms_noise: 0.5
transforms_gain: 0.0
transforms_filters: 0.4
transforms_highpass_freq: 800
transforms_lowpass_freq: 3500



## reload options
reload: False
model_path: "" # set to the directory containing `checkpoint_##.tar` 
epoch_num: 0 # set to checkpoint number


## linear evaluation options
mlp: True 
logistic_batch_size: 64
logistic_epochs: 100
logistic_lr: 0.003 # clmr: 0.0004, cpc: 0.003
reload_logreg: False
perc_train_data: 1.0
logreg_model_path: ""
logreg_epoch_num: ""
num_tags: 50
at_least_one_pos: False

### vision
## model options
# resnet: "resnet50"

## dataset options
# image_height: 220
# image_width: 120
# image_channels: 1


# universal_symbol_processed: "./datasets/vision/universal_symbol"
# image_height: 96
# image_width: 96
# image_channels: 3


