## task / dataset options
domain: "audio" # [audio,scores]
task: "tags" # [tags,chords,symbol]
dataset: "gtzan" # [audio: [billboard,fma,magnatagatune,gtzan] vision: [deepscores,universal]]
data_input_dir: "datasets/audio" # [audio: [datasets/audio] vision: [datasets/vision]
model_name: "clmr" # [clmr, supervised]

## train options
seed: 42 # sacred handles automatic seeding when passed in the config
batch_size: 48 # for audio, 256 for images
num_workers: 16
start_epoch: 0
epochs: 10000

## loss options
optimizer: "Adam" # [Adam, LARS]
learning_rate: 3.0e-4 # for Adam optimizer, LARS uses batch-specific LR
weight_decay: 1.0e-6
temperature: 0.5 # (NOTE: 0.1 goes very fast) see appendix B.7.: Optimal temperature under different batch sizes


## supervised params (if model_name == supervised)
supervised_lr: 0.01

## model options
normalize: True
projection_dim: 128
dropout: 0.5

## audio
audio_length: 59049
sample_rate: 22050

## transformations
transforms_phase: 0.8
transforms_noise: 0.5
transforms_gain: 0.0
transforms_filters: 0.4
transforms_highpass_freq: 800
transforms_lowpass_freq: 3500



## mixed-precision training
# fp16: False 
# fp16_opt_level: "O2"


## reload options
reload: False
model_path: "" # set to the directory containing `checkpoint_##.tar` 
epoch_num: "" # set to checkpoint number


## linear evaluation options
mlp: True 
logistic_batch_size: 64
logistic_epochs: 275
logistic_lr: 0.0004
reload_logreg: False
perc_train_data: 1.0
logreg_model_path: ""
logreg_epoch_num: ""
num_tags: 50

### vision
## model options
# resnet: "resnet50"

## dataset options
# image_height: 220
# image_width: 120
# image_channels: 1


# universal_symbol_processed: "./datasets/vision/universal_symbol"
# image_height: 96
# image_width: 96
# image_channels: 3
